---
layout: post
title: "Very Deep Convolutional Networks for Large-Scale Image Recognition"
date: 2021-01-25
category: review
thumbnail: /style/image/VGG.png
use_math: true
icon: book
---

* contents
{:toc}

<span style="font-size:13pt">Karen Simonyan, Andrew Zisserman</span>

# Abstact

- **ë³¸ ë…¼ë¬¸ì—ì„œëŠ” large-scale image recognition settingì—ì„œ CNNì˜ ê¹Šì´ê°€ accuarcyì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ê´€í•œ ì—°êµ¬ ì§„í–‰**
- **ì£¼ìš” ê¸°ì—¬**: ë§¤ì£¼ ì‘ì€ (3x3) convolution filterë¥¼ ì‚¬ìš©í•´ì„œ ê¹Šì´ë¥¼ ì¦ê°€ì‹œí‚¤ë©´ì„œ networkë¥¼ í‰ê°€ (16-19 weight layerë¥¼ ìŒ“ì•„ì„œ ì´ì „ ë³´ë‹¤ ìƒë‹¹íˆ ê°œì„ í•¨)
- ë‹¤ë¥¸ ë°ì´í„° ì…‹ì—ì„œë„ ì¼ë°˜í™”ë˜ì–´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆì—ˆê³ , ë‘ ê°€ì§€ ìµœê³  ì„±ëŠ¥ì˜ ConvNet ëª¨ë¸ì„ ê³µê°œ

# 1. Introduction

- Convolutional Networks (ConvNets)ì€ ìµœê·¼ large-scale ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ì¸ì‹ì—ì„œ ì•„ì£¼ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„
    - deep ConvNets(2012)ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì—¬ëŸ¬ ì‹œë„ë¥¼ ì§„í–‰
        1. ì²« ë²ˆì§¸ convolutional layerì˜ stridì™€ window sizeë¥¼ ë” ì‘ê²Œ ì‚¬ìš©í•˜ëŠ” ê²ƒ(2013)
        2. ì „ì²´ ì´ë¯¸ì§€ì™€ ì—¬ëŸ¬  í¬ê¸°ì— ê±¸ì³ ì¡°ë°€í•˜ê²Œ networkë¥¼ í›ˆë ¨í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒ(2014)
- ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ConvNet architecture ì„¤ê³„ì˜ ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ì¸¡ë©´ì¸ "**ê¹Šì´, depth**"ì— ëŒ€í•´ ë‹¤ë£¸
    - ì´ë¥¼ ìœ„í•´ **ëª¨ë“  layerì—ì„œ (3x3)ì˜ ë§¤ì£¼ ì‘ì€ convolution filterë¥¼ ì‚¬ìš©**í•˜ì—¬ networkì˜ ê¹Šì´ë¥¼ ê³„ì† ì¦ê°€ì‹œí‚´
    â€” parameter ìˆ˜ë¥¼ ì¤„ì„ìœ¼ë¡œì¨ ì¼ë°˜í™”ê°€ ë” ìš©ì´, overfittingì„ ë§‰ê³ , ì—°ì‚°ëŸ‰ì„ ì¤„ì„
    - ê²°ê³¼ì ìœ¼ë¡œ classificationê³¼ **localisation tasks**ì— ëŒ€í•œ ê°€ì¥ ì¢‹ì€ ì •í™•ë„ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ ì¸ì‹ ë°ì´í„° ì…‹ì—ë„ ì ìš©í•  ìˆ˜ ìˆëŠ” í›¨ì”¬ ë” ì •í™•í•œ ConvNet architectureë¥¼ ê°œë°œ

**localisation tasks**
objectê°€ ìˆëŠ” ìœ„ì¹˜ë¥¼ ì°¾ì•„ ê·¸ ì£¼ìœ„ì— bounding boxë¥¼ ê·¸ë¦¬ëŠ” ê²ƒ

â“â“â“

**large public image repositories**
ê¸°ì¡´ì—ëŠ” ì´ë¯¸ì§€ ë§ì§€ ì•Šì•„ì„œ í›ˆë ¨ì´ í¬ê²Œ, ë§ì´ í•  ìˆ˜ ì—†ì—ˆëŠ”ë° ImageNet(image database)ê³¼ ê°™ì€ ì €ì¥ì†Œê°€ ìƒê²¨ì„œ ì´ëŸ¬í•œ ë¬¸ì œì ì„ í•´ê²°í•  ìˆ˜ ìˆì—ˆìŒ
**high-dimensional shallow feature**
ë†’ì€ ì°¨ì›ì˜ ë°ì´í„°ë¥¼ í•™ìŠµ ê³„ì¸µì„ ì ê²Œ ì‚¬ìš©í•´ì„œë„ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í–ˆë‹¤? â€” ë”¥ëŸ¬ë‹ì´ ìœ í–‰í•˜ê¸° ì „ì—ëŠ” ìë™ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼, í•„í„°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì†ìœ¼ë¡œ ë§Œë“¤ì–´ ì‚¬ìš©í–ˆëŠ”ë° ìƒëŒ€ì ìœ¼ë¡œ dimensionì´ í¬ê³  ë³µì¡í•œë° ì˜ˆì „ ëª¨ë¸ì„ ì¼ì»«ëŠ” ê²ƒ ê°™ìŒ

**testbed**
imageë¥¼ í™œìš©í•´ì„œ ë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” ë¬¸ì œë‚˜ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì¥ì†Œ

**used as a part of a relatively simple pipelines**

ë‹¤ë¥¸ ëª¨ë¸ê³¼ í•©ì³ì„œ ì‚¬ìš©í•  ë•Œ ì•ë‹¨ì— ë§ì´ ì‚¬ìš©ë¨

# 2. ConvNet Configurations

### 2.1 Architecture

> **Conv layer**

- **feature extractor**
- input: fixed-size 224x224 RGB (preprocessing: ê° channelì— ëŒ€í•´ meanë¹¼ëŠ” ê²ƒ â€” data centering)
    - ìŒìˆ˜~ì–‘ìˆ˜ë¡œ ê°’ì˜ ë²”ìœ„ë¥¼ ë§ì¶¤
- (3x3) filterë¥¼ ì‚¬ìš©í•˜ëŠ” convolutional layerë¥¼ ìŒ“ì€ êµ¬ì¡°
    - 3x3 filter: ìœ„/ì•„ë˜, ì™¼ìª½/ì˜¤ë¥¸ìª½, ì¤‘ì•™ì˜ ì •ë³´ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í¬ê¸°
- 1x1 convolution filterë„ ì‚¬ìš©
    - input channelsì˜ linear transformationì„ ìœ„í•´
- stride: 1, padding ì ìš© O

> **Spatial Pooling layer**

- conv layer ì´í›„ ì ìš© (ëª¨ë“  conv ì´í›„ì— ì‚¬ìš©ë˜ì§€ëŠ” ì•ŠìŒ)
- ì´ 5ê°œì˜ max poolinhg layer ì‚¬ìš©
    - 2x2 size, stride: 2

â“â“â“

**Spatial Pooling layer = Spatial Pyramid Pooling? No!**

~~ë§Œì•½ ë‘ê°œê°€ ê°™ë‹¤ë©´ ì´ë¯¸ì§€ ì¸ì‹ì—ì„œ ì¼ì •í•œ í¬ê¸°ë¡œ ìë¥´ê±°ë‚˜ ì¶•ì†Œí•´ì„œ ëª¨ë¸ì— ë„£ì€ê²Œ ì•„ë‹ˆë¼ í†µì±„ë¡œ ë„£ê³  poolingì„ ì´ìš©í•´ì„œ ì¼ì •í•œ í¬ê¸°ë¡œ ë§ì¶”ì„œ FC ì…ë ¥ìœ¼ë¡œ ë„£ëŠ” ê²ƒ ê°™ì€ë° ë’¤ì—ì„œ í›ˆë ¨í•  ë•Œ íŠ¹ì • ì°¨ì›ìœ¼ë¡œ ë§ì¶”ëŠ” ê²ƒ ê°™ì€ë° ì™œ ì´ ë°©ë²•ì€ ì‚¬ìš©í•˜ëŠ” ê²ƒì¸ì§€?~~

â†’ 10x10ì´ ìˆìœ¼ë©´ ì´ê±¸ ì¤„ì—¬ì„œ strideì— ë§ì¶° 5x5ë¡œ ì¤„ì´ëŠ” ê²ƒ (ì¼ë°˜ì ì¸ poolingì´ë‘ ê°™ìŒ)

> **Fully-connected layer (FC)**

- **convì—ì„œ ë‚˜ì˜¨ featureë¡œ í™•ë¥ ê°’ì„ ì´ìš©í•´ classification**
- 3ê°œì˜ FC ì‚¬ìš© + softmax layer
    - 1-2 layer: 4096ê°œ node, 3 layer: 1000 (classificationì„ ìœ„í•´)
- activation function: ReLU
- Local Response Normalization (LRN) ì •ê·œí™” í¬í•¨X (í•˜ë‚˜ ì œì™¸í•˜ê³ )
    - ReLUë¥¼ ì‚¬ìš©í•˜ë©´ ì–‘ìˆ˜ê°’ì€ ìê¸° ìì‹ ì´ ë‚˜ì˜¤ê²Œ ë˜ì–´, ë§¤ìš° í° ê°’ì„ ê°–ëŠ” ê²½ìš°(outlier) ë‹¤ë¥¸ ê°’ë“¤ì´ ê¸°ëŠ¥ì„ ëª»í•  ìˆ˜ ìˆìŒ
    - ReLU ì´í›„ì— ë‚˜ì˜¤ëŠ” ê°’ì„ ì£¼ë³€ ê°’ì„ ì´ìš©í•´ normalizeí•´ì¤Œìœ¼ë¡œì¨ ì´ëŸ¬í•œ ê²ƒì„ ì™„í™”

### 2.2 Confiurations

- ê¹Šì´ê°€ ë” ê¹Šì–´ì§ì—ë„ ë¶ˆêµ¬í•˜ê³  ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” networkì— ìˆëŠ” ê°€ì¤‘ì¹˜ì˜ ìˆ˜ëŠ” ë” ì–•ê³  í° convë¥¼ ê°–ëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ìˆ˜ë³´ë‹¤ í¬ì§€ ì•ŠìŒ
    - Sermanet et al., 2014: 144M weights

<center><img src="https://user-images.githubusercontent.com/46676700/124697233-67018600-df21-11eb-86c6-962f45358b86.png" alt="img" style="zoom: 80%;" /></center>

### 2.3 Discussion

> **ì°¨ë³„ì **

- stride=4 11x11 filter, stride=2 7x7 filterì™€ ê°™ì´ í° filterë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ì „ ëª¨ë¸ë“¤ê³¼ ë‹¬ë¦¬ **3x3ì˜ ë§¤ìš° ì‘ì€ sizeì˜ filterë¥¼ ì‚¬ìš©**

> **3x3 filterë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ **

Table1ì—ì„œ ì¤‘ê°„ì— spatial poolingì´ ì—†ëŠ” ê²½ìš° ì—¬ëŸ¬ ê°œì˜ convê°€ stackë˜ì–´ ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ

- 2ê°œë¥¼ ì‚¬ìš©í•˜ê²Œë˜ë©´ 5x5 filterë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ (= effective receptive fieldê°€ ê°™ìŒ)
    - 3ê°œ ì‚¬ìš©: 7x7

**â†’ ì–»ëŠ” ì´ì ì€?**

1. activation functionì„ ë” ë§ì´ ê±°ì¹˜ë©´ì„œ non-linearí•œ ë¬¸ì œë¥¼ ë” ì˜ í’€ ìˆ˜ ìˆê²Œ ë¨
2. parameterì˜ ìˆ˜ë¥¼ ì¤„ì„
    - Cì±„ë„ì˜ 3x3 convolutionì´ 3 layerì¸ ê²½ìš°: $3(3^2C^2) = 27C^2$
    - Cì±„ë„ 7x7 convolutionì´ 1 layerì¸ ê²½ìš°: $7^2(C^2)=49C^2$

+ decision functionì˜ ë¹„ì„ í˜•ì„±ì„ ì¦ê°€ì‹œí‚¤ê¸° ìœ„í•´ 1x1 convë¥¼ ì‚¬ìš©
â€” ë¹„ì„ í˜•ì„±ì„ ì¦ê°€ì‹œí‚¤ë©´ ì¢€ ë” ë³µì¡í•œ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆê²Œ ë¨

> **ìœ ì‚¬í•œ task**

- Lin et al.(2014)
  â€” "Network in Network"ì—ì„œ 1x1 convê°€ í™œìš©ë¨, ê·¸ëŸ¬ë‚˜ ë³¸ ë…¼ë¬¸ì˜ êµ¬ì¡°ë³´ë‹¤ ê¹Šì§€ ì•Šìœ¼ë©° ILSVRC ë°ì´í„° ì…‹ì—ì„œ í‰ê°€í•˜ì§€ ì•ŠìŒ  

- Goodfellow et al.(2014)
  â€” ê±°ë¦¬ ë²ˆí˜¸ ì¸ì‹ì—ì„œ ê¹Šì€ ConvNetsì„ ì ìš©í–ˆê³  ê¹Šì´ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì„±ëŠ¥ì´ í–¥ìƒë¨ì„ ë³´ì—¬ì¤Œ  

- Szegedy et al.(2014)
  â€”"GoogLeNet" ë§¤ìš° ê¹Šì€ ConvNet(22 layer)ì™€ ì‘ì€ convolutionì„ ê¸°ë°˜í•œë‹¤ëŠ” ì ì—ì„œ ìœ ì‚¬í•¨ (1x1, 5x5 ì‚¬ìš©), ë³¸ ë…¼ë¬¸ë³´ë‹¤ network topologyê°€ ë³µì¡í•˜ê³  ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ ë¶„ë¥˜ì—ì„œ ë³¸ ë…¼ë¬¸ ì„±ëŠ¥ì´ ë” ìš°ìˆ˜

# 3. Classification Framework

### 3.1 Training

> **hyperparameter**

- cost function: Cross Entropy
- mini-batch size: 256
- optimizer: Momentum=0.9
- regularization: L2 regularization($5 Â· 10^{âˆ’4}$), Dropout(0.5)
- learning rate: $10^{-2}$ (validation accuarcyì˜ ì¦ê°€ê°€ ë©ˆì¶”ë©´ 0.1ì”© ê°ì†Œ â€” 3ë°° ê°ì†Œ)
- 370L iterations (74 epochs)
- pre-initialization: A modelì˜ ì¼ë¶€(ì²˜ìŒ 4ê°œ conv+ë§ˆì§€ë§‰ 3ê°œ FC)ë¥¼ í›ˆë ¨í•œ ë’¤ ê°€ì ¸ì™€ì„œ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©

> **Training image size**

**isotropically-rescaled**

- imageë¥¼ VGG model input size(224x224)ì— ë§ë„ë¡ ë³€ê²½í•´ì¤˜ì•¼ í•¨
- **Së¥¼ ì´ìš©**í•´ì„œ **ë¹„ìœ¨ì€ ê·¸ëŒ€ë¡œ** ë‘ê³  sizeë¥¼ ë°”ê¾¼ ë’¤ **cropí•˜ì—¬ ì‚¬ìš©**

**training scale S**

1. Së¥¼ ê³ ì •ì‹œí‚¤ëŠ” ê²ƒ
    - S=256ìœ¼ë¡œ ë‘ì–´ ë¨¼ì € networkë¥¼ í›ˆë ¨í•˜ê³ , S=384ë¡œ í›ˆë ¨í•  ë•ŒëŠ” 256ìœ¼ë¡œ í›ˆë ¨í•œ íŒŒë¼ë¯¸í„°ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ì‚¬ìš©í•˜ê³ , ë” ì‘ì€ learning rate ì‚¬ìš© ($10^{-3}$)

2. 256~512 ì¤‘ randomí•˜ê²Œ Sê°’ ì‚¬ìš© (multi-scale)
    - objectê°€ ëª¨ë‘ ë‹¤ë¥¸ sizeë¥¼ ê°–ìœ¼ë©´ì„œ í•™ìŠµíš¨ê³¼ê°€ ë” ì¢‹ì•„ì§ˆ ìˆ˜ ìˆìŒ
    - data augmentation íš¨ê³¼(= scale jittering)

### 3.2 **Testing**

trainì— ì‚¬ìš©ëœ Sì™€ ê°™ì€ ì—­í• ì„ í•˜ëŠ” **Q** ë¥¼ ì‚¬ìš©í•˜ì—¬ **image rescaling** ì ìš©

- $Q \ne S$

**êµ¬ì¡° ë³€ê²½** (cropí•˜ì§€ ì•Šì€ ì „ì²´ ì´ë¯¸ì§€ì— ì ìš©í•  ìˆ˜ ìˆìŒ)

- FC layer â†’ conv
    - first: **7x7 conv**
    - last two: **1x1 conv**

â†’ class ìˆ˜ì™€ ë™ì¼í•œ channel ìˆ˜ì™€ input image sizeì— ë”°ë¼ ê°€ë³€ ê³µê°„ í•´ìƒë„ë¥¼ ê°–ëŠ” class score map

**ê³ ì • í¬ê¸°ì˜ ë²¡í„°**

- class scoreë¥¼ ì–»ê¸° ìœ„í•´ pooling ì§„í–‰(spatially averaged)
- imageë¥¼ ìˆ˜í‰ìœ¼ë¡œ ë’¤ì§‘ì–´ì„œ, ì›ë³¸ ì´ë¯¸ì§€ì™€ ë’¤ì§‘íŒ ì´ë¯¸ì§€ì˜ softmax ê²°ê³¼ë¥¼ í‰ê· ë‚´ ìµœì¢… scoreë¡œ ì‚¬ìš©

---

**Reference**

- paper [[ğŸ“‘](https://arxiv.org/pdf/1409.1556.pdf)]
- CNNì˜ parameter ê°œìˆ˜ì™€ tensor ì‚¬ì´ì¦ˆ ê³„ì‚°í•˜ê¸° [[ğŸ‘†](https://seongkyun.github.io/study/2019/01/25/num_of_parameters/)]
