---
layout: default
title: "Adversarial on Short Utterances"
parent: "Paper review"
nav_order: 8
permalink: /docs/review/8
use_math: true
comments: true
---

# **Text-Independent Speaker Verification with Adversarial Learning on Short Utterances**

#### Kai Liu, Huan Zhou

<br/>

### :pushpin: Abstract

**ë¬¸ì œì :** Text-independent speaker verificationì€ ì§§ì€ ë°œí™” ì¡°ê±´ì—ì„œ ì‹¬ê°í•œ ì„±ëŠ¥ ì €í•˜ë¥¼ ê²ªìŒ
**í•´ê²°ë°©ë²•:** short embeddingì„ enhanced embeddingì— ì§ì ‘ ë§¤í•‘í•˜ì—¬ íŒë³„ë ¥(discriminability)ì„ ë†’ì´ë„ë¡ adversarialí•˜ê²Œ í›ˆë ¨ëœ embedding model ì œì•ˆ

- íŠ¹íˆ, loss criteria(ê¸°ì¤€)ì´ ë§ì€ <span style="background-color:#AED6F1">**Wasserstein GAN**</span> ì‚¬ìš©
- ì—¬ëŸ¬ loss functionì€ ëšœë ·í•˜ê²Œ ìµœì í™”í•˜ë ¤ëŠ” ëª©í‘œë¥¼ ê°€ì§€ê³  ìˆìœ¼ë‚˜ ê·¸ ì¤‘ ì¼ë¶€ëŠ” í™”ì ê²€ì¦ ì—°êµ¬ì— ë„ì›€ì´ ë˜ì§€ ì•ŠìŒ
- ëŒ€ë¶€ë¶„ì˜ ì´ì „ ì—°êµ¬ì™€ ë‹¬ë¦¬  <span style="background-color:#AED6F1">**ì´ ì—°êµ¬ì˜ ì£¼ìš” ëª©í‘œ** ëŠ” **ìˆ˜ë§ì€ ablation ì—°êµ¬** ë¡œ ë¶€í„° loss criteriaì˜ íš¨ê³¼ë¥¼ ê²€ì¦</span>
ã€€â†’ ìœ„ì—ì„œ ë§í•˜ëŠ” SVì—ì„œ ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” lossë“¤ì„ ì œê±°í•˜ë©´ì„œ lossì— ë”°ë¥¸ ì˜í–¥ì„ ì¡°ì‚¬
- VoxCeleb datasetì— ëŒ€í•œ ì‹¤í—˜ì—ì„œ ì¼ë¶€ criteriaëŠ” SV ì„±ëŠ¥ì— ì´ë¡œìš´ ë°˜ë©´ ì¼ë¶€ criteriaëŠ” ì‚¬ì†Œí•œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œ
- ë§ˆì§€ë§‰ìœ¼ë¡œ, finetuningì—†ì´ ì‚¬ìš©í•œ Wasserstein GANì€ baselineì„ ë„˜ì–´ ì˜ë¯¸ ìˆëŠ” ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•˜ë©°, EERì—ì„œëŠ” 4%ì˜ ìƒëŒ€ì  ê°œì„ ê³¼ 2ì´ˆê°„ì˜ ì§§ì€ ë°œí™”ì˜ challengeí•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” 7%ì˜ minDCFë¥¼ ë‹¬ì„±


---


### â… . Introduction :seedling:

- TI-SV: ë“±ë¡ëœ í™”ìì™€ í…ŒìŠ¤íŠ¸ ìŒì„±(ë‚´ìš© ì œì•½ X)ì„ í†µí•´ í™”ìì˜ ì‹ ì›ì„ ê²€ì¦
- ì¤‘ìš”í•œ ë‹¨ê³„: ì„ì˜ì˜ ì§€ì†ì‹œê°„ì„ ê°–ëŠ” ìŒì„±ì„ ê³ ì • ì°¨ì›ì˜ speaker representationìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ê²ƒ (acoustic feature â†’ speaker feature)
- Baseline System: GhostVLAD-aggregated embedding(G-vector); ê¸´ ë°œí™”, ì§§ì€ ë°œí™”ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì¡ìŒ í™˜ê²½ì—ì„œ x-vectorë³´ë‹¤ ì´ì ì´ ìˆì–´ SV ì‹œìŠ¤í…œì— ë” ìœ ë¦¬
- NIST-SRE 2010 test setì—ì„œ **full-durationì´ 5ì´ˆë¡œ ë‹¨ì¶•**ë˜ì—ˆì„ ë•Œ i-vector/PLDA system **ì„±ëŠ¥ì´ 2.48%ì—ì„œ 24.78%** ë¡œ ê°ì†Œ, **ìµœê·¼ ë”¥ëŸ¬ë‹ ê¸°ìˆ  ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ë³´ì™„í•˜ëŠ” ì—°êµ¬ê°€ ë§ì´ ì§„í–‰ ì¤‘**
- ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Wasserstein GANì˜ adversarial í•™ìŠµì„ ì´ìš©í•˜ì—¬ í–¥ìƒëœ ì°¨ë³„ì„±ì„ ê°€ì§„ ìƒˆë¡œìš´ embeddingì„ ì œì•ˆ
(ê°™ì€ í™”ìì˜ ì§§ì€ ë°œí™”ì™€ ê¸´ ë°œí™”ì—ì„œ ì¶”ì¶œí•œ G-vectorë¥¼ í™œìš©í•˜ì—¬)


---


### â…¡. Related Work :herb:

**âœ” GAN ì´ë€**: ìƒì„±ì(Generator)ì™€ ì‹ë³„ì(Discriminator)ê°€ ì‹¸ìš°ë©´ì„œ í•™ìŠµí•˜ëŠ” ëª¨ë¸
- Generator : Discriminatorë¥¼ ì†ì´ë„ë¡ í•™ìŠµ
- Discriminator : real sample ğ‘¦ì™€ noise ğœ‚ë¡œë¶€í„° ìƒì„±ëœ fake sample ğ‘”ì˜ ì°¨ì´ë¥¼ í•™ìŠµ

</br>

**âœ” Adversarial Learning**
- minmax loss functionì´ êµëŒ€ë¡œ ìµœì í™” ê³¼ì •ì„ ìˆ˜í–‰ (ë‘ ëª¨ë¸ì˜ lossê°€ ê°™ì•„ì§€ëŠ” ìƒíƒœê°€ ë  ë•Œê¹Œì§€)

<center><img src="https://user-images.githubusercontent.com/46676700/101442311-735b3b80-395e-11eb-87da-130ab93a5834.png" alt="img"/></center>

- Gradients diminishing, exploding ë¬¸ì œë¡œ í›ˆë ¨í•˜ê¸° ì–´ë ¤ìš´ë° ì´ë¥¼ Wasserstein GAN(WGAN)ì—ì„œ ìˆ˜í•™ì ìœ¼ë¡œ ë‹¤ë£¨ì—ˆìŒ
- DiscriminatorëŠ” ì¢‹ì€ $ğ‘“_ğ‘¤$ë¥¼ ì°¾ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ìƒˆë¡œìš´ loss functionì€ Wasserstein ê±°ë¦¬ë¥¼ ì¸¡ì •í•˜ë„ë¡ êµ¬ì„±


<center><img src="https://user-images.githubusercontent.com/46676700/101442322-76eec280-395e-11eb-8f23-77c965f91d6a.png" alt="img"/></center>


---


### â…¢. Proposed Approach :deciduous_tree:

- ì œì•ˆí•˜ëŠ” ì „ê¸‰ ë°©ì‹ì€ ì•„ë˜ì˜ êµ¬ì¡°ì™€ ê°™ìŒ

<center><img src="https://user-images.githubusercontent.com/46676700/101442513-ccc36a80-395e-11eb-923b-4ca1aa2ac183.png" alt="img"/></center>

> $ğ‘¥, ğ‘¦$ : ê°™ì€ speakerì˜ ê°ê° ì§§ê³  ê¸´ ë°œí™”ì— í•´ë‹¹í•˜ëŠ” Dì°¨ì›ì˜ G-vector
>
> $ğ‘§$ : speaker ID label
>
> $ğº_ğ‘“$ : embedding generator
>
> $ğº_ğ‘$ : speaker label predictor
>
> $ğº_ğ‘‘$ : Distance calculator
>
> $ğ·_ğ‘¤$ : Wasserstein discriminator

<br/>

- ì œì•ˆëœ ë°©ë²•ì˜ **í•µì‹¬ì ì¸ task**ëŠ” **discriminabilityì´ í–¥ìƒëœ embeddingì„ í•™ìŠµ**í•˜ëŠ” ê²ƒ

<span style="background-color:#E4C4F0">**âœ” loss functions**</span>

- **WGAN loss**
<center><img src="https://user-images.githubusercontent.com/46676700/101443118-02b51e80-3960-11eb-86ce-40b44aed35fc.png" alt="img"/></center>

<br/>

- **Conditional WGAN loss**: GANì— Wasserstein ê±°ë¦¬ë¥¼ ì´ìš©í•œ ìƒˆë¡œìš´ loss function ì •ì˜

  - $ğ‘¥$ (ì§§ì€ ë°œí™” embedding)ì´ ì£¼ì–´ì¡Œì„ ë•Œ, $ğ·_ğ‘¤$ì™€ $ğº_ğ‘“$ ë¶„í¬ì˜ ì°¨ì´ ($ğ‘¥$ì™€ real sample, fake sampleì„ ì—°ê²°í•˜ì—¬ í•™ìŠµ)


<center><img src="https://user-images.githubusercontent.com/46676700/101443121-047ee200-3960-11eb-85e3-d6cdb120eb2f.png" alt="img"/></center>

<br/>

:zap: WGAGN loss / Conditional WGAN loss ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ê³ , ê·¸ ì°¨ì´ë¥¼ ì„±ëŠ¥ í‰ê°€ ì‹¤ì‹œ

</br>

- **FID loss**: FrÃ©chet Inception Distance

  - Real sampleê³¼ fake sampleì˜ ë²¡í„° ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚°ì„ ìœ„í•œ metric

<center><img src="https://user-images.githubusercontent.com/46676700/101443125-05b00f00-3960-11eb-83a1-b11abcfe6840.png" alt="img"/></center>

<br/>

- **class loss**: Multi-class cross-entropy loss

  - Speakerì— ë”°ë¥¸ embedding ì°¨ì´ë¥¼ ìœ„í•œ loss ì •ì˜

<center><img src="https://user-images.githubusercontent.com/46676700/101443129-08126900-3960-11eb-98d6-16200989d2ff.png" alt="img"/></center>

> $ğ‘$ : Batch size
>
> $ğ‘$ : Class ìˆ˜
>
> $ğ‘”_ğ‘–$ : ië²ˆì§¸ ìƒì„±ëœ embedding
>
> $ğ‘§_ğ‘–$ : í•´ë‹¹ label index
>
> $ğ‘Šâˆˆâ„œ^(ğ·âˆ—ğ‘), ğ‘âˆˆâ„œ^ğ‘$ : weight matrix, bias


<br/>

- **Triplet loss**

  - Class ë¶„ë¥˜ ì‹œ errorì— ëŒ€í•œ íŒ¨ë„í‹°

<center><img src="https://user-images.githubusercontent.com/46676700/101443133-09dc2c80-3960-11eb-882f-caf3570671b9.png" alt="img"/></center>

> $\Gamma$ : training setì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  embeddingì˜ triplet $\gamma=(ğ‘”_ğ‘, ğ‘”_ğ‘, ğ‘”_ğ‘›)$ì˜ set
>
> $ğ‘”_ğ‘$ : anchor input
>
> $ğ‘”_ğ‘$ : positive input
>
> $ğ‘”_ğ‘›$ : negative input
>
> $\Psiâˆˆâ„œ^+$ : positiveì™€ negative ì‚¬ì´ì˜ safety margin


<br/>

- **Center loss**

  - Class ë‚´ variation ìµœì†Œí™”

<center><img src="https://user-images.githubusercontent.com/46676700/101443140-0c3e8680-3960-11eb-8896-37b5be81d367.png" alt="img"/></center>

> $ğ‘_(ğ‘¦_ğ‘–)$ : deep featureì˜ ğ‘¦_ğ‘–ë²ˆì§¸ class center
> $ğ‘¥_ğ‘–$ : $ğ‘¦_ğ‘–$ë²ˆì§¸ classì— ì†í•˜ëŠ” ğ‘–ë²ˆì§¸ deep feature
> $ğ‘š$ : mini-batch size


<br/>

- **Cosine distance loss**

  - Generator modelë¡œ ì–»ì€ í–¥ìƒëœ embeddingê³¼ real sample(target) ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ê³ ë ¤

<center><img src="https://user-images.githubusercontent.com/46676700/101443144-0ea0e080-3960-11eb-8437-04997a2f26bc.png" alt="img"/></center>

> $\bar ğ‘’$: normalized embedding

<br/>

:star: <span style="background-color:#FFED81">**âœ” Generatorì™€ Discriminatorì˜ ìµœì¢… Loss**</span>

- $G_f$

<center><img src="https://user-images.githubusercontent.com/46676700/101444427-d3ec7780-3962-11eb-8967-3f0ff2912fad.png" alt="img"/></center>

- $D_w$

<center><img src="https://user-images.githubusercontent.com/46676700/101444430-d5b63b00-3962-11eb-97a0-807326d8a4a4.png" alt="img"/></center>


- WGAN í›ˆë ¨ í›„ generative model $ğº_ğ‘“$ ìœ ì§€

  - Test ë‹¨ê³„ì—ì„œ ì§§ì€ ë°œí™” embedding $ğ‘¥$ë¥¼ $ğº_ğ‘“$ì— ë„£ì–´ enhanced embedding($g$)ë¥¼ ì–»ìŒ


---

### â…£. Experiments and Results :hibiscus:

**âœ” Experimental setup**

- **Train:**  VoxCeleb2ì˜ subset (1,057ëª… í™”ìì˜ 164,716ê°œ ë°œí™”)
- **Test:**   VoxCeleb1ì˜ subset (40ëª… í™”ìì˜ 13,265ê°œ ë°œí™”)
- ì§§ì€ ë°œí™”ë¥¼ ìœ„í•´ **randomí•˜ê²Œ 2ì´ˆ ì˜ë¼ì„œ** ì‚¬ìš©

**âœ” Baseline system**

- G-vector (VGG-Restnet34s)

**âœ” Hyper Parameter**

- Learning rate 0.0001
- Adam Optimizer
- Weight clipping -0.01 ~ 0.01 threshold ($ğ·_ğ‘¤$)
- Batch size 128

<br/>

<span style="background-color:#AED6F1">**âœ” ë‹¤ì–‘í•œ loss functionì˜ ì˜í–¥ ì—°êµ¬**</span>

<center><img src="https://user-images.githubusercontent.com/46676700/101445011-0d71b280-3964-11eb-8d77-389d6aa37ee3.png" alt="img"/></center>
<center><img src="https://user-images.githubusercontent.com/46676700/101445016-0f3b7600-3964-11eb-94f9-767587338bcc.png" alt="img"/></center>

<center> - FID lossì€ ê¸ì •ì ì¸ ì˜í–¥ (v1 vs v2) </center>
<center> - Conditional WGANì´ WGANë³´ë‹¤ ë‚˜ìŒ (v3 vs v4) </center>
<center> - Triplet lossë¥¼ ë„£ìœ¼ë©´ ì¡°ê¸ˆ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë³´ì„ (v7 vs v2) </center>
<center> - Triplet b(fake)ë³´ë‹¤ Triplet a(real, fake ëª¨ë‘)ê°€ í¬ê²Œ ì„±ëŠ¥ í–¥ìƒ (v3 vs v8) </center>
<center> - SoftmaxëŠ” ê¸ì •ì ì¸ ì˜í–¥ (v3 vs v5) </center>
<center> - Center lossì€ ë¶€ì •ì ì¸ ì˜í–¥ (v6 vs v7) </center>
<center> - Cosine lossì€ ê¸ì •ì  ì˜í–¥ (v6 vs v8) </center>

<br/>

- **ì¶”ê°€ì ì¸ training function**(softmax, cosine, triplet)ì´ ëª¨ë‘ **í›ˆë ¨ì— ê¸ì •ì ì¸** ì˜í–¥ì„ ë¯¸ì¹¨
- SVì‹œìŠ¤í…œì— FID, conditional WGANì€ ë§¤ìš° ìœ ìš©, ì¶”ê°€ ì¡°ì‚¬ ê°€ì¹˜ê°€ ìˆìŒ

<br/>

**âœ” Baseline systemê³¼ ë¹„êµ**

- ì‹¤í—˜ ì¤‘ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ v3 systemê³¼ G-vector baseline system ë¹„êµ
  - EERê³¼ minDCF

<center><img src="https://user-images.githubusercontent.com/46676700/101445333-a6083280-3964-11eb-86af-900deb097f6e.png" alt="img"/></center>

<br/>

- Baselineë³´ë‹¤ ì§§ì€ durationì— ëŒ€í•´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì„
  - ìƒëŒ€ì ìœ¼ë¡œ EERì€ 4.2% ê°œì„ í•˜ì˜€ìœ¼ë©°, minDCFëŠ” 7.2% ê°œì„  â€“ 1ì´ˆ taskì—ì„œë„ ìƒëŒ€ì  EER 3.8% í–¥ìƒ
- ì‹œê°„ ì œì•½ìœ¼ë¡œ FID lossëŠ” ìµœì¢… systemì— ì¶”ê°€í•˜ì§€ ì•Šì•˜ìœ¼ë©° hyper-parameter, loss weight($\alpha, \beta, \gamma, \lambda, \epsilon$)ì™€ triplet margin $\Psi$ì— ëŒ€í•œ ë¯¸ì„¸ì¡°ì •ì´ ì—†ì—ˆìŒ
  - ì œì•ˆí•œ systemì˜ ê°œì„ ë  ì—¬ì§€ê°€ ë§ì´ ë‚¨ì•„ìˆìŒ



---

### â…¤. Conclusion :sun_with_face:

- ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **WGANì„ ì ìš©** í•˜ì—¬ **ë°œí™”ê°€ ì§§ì€** speaker verification applicationì˜ **í–¥ìƒëœ embeddingì„ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµ**
- ì œì•ˆëœ WGAN ê¸°ë°˜ ì»¤ë„ ì‹œìŠ¤í…œ ê·¸ë¦¬ê³  ê·¸ ìœ„ì—, GAN í›ˆë ¨ì—ì„œ **ë§ì€ loss criteriaì˜ íš¨ê³¼ë¥¼ ê²€ì¦**
- ìµœì¢… ì œì•ˆ ì‹œìŠ¤í…œì€ ë„ì „ì ì¸ ì§§ì€ ìŠ¤í”¼ì»¤ ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ baseline systemì„ ëŠ¥ê°€
- ì „ë°˜ì ìœ¼ë¡œ, ìƒë‹¹í•œ ì§„ë³´ì™€ ì—°êµ¬ê°€ ì§„ì „ë˜ëŠ” ì ì¬ì  ë°©í–¥ì„ ë³´ì—¬ì¤Œ
