<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta http-equiv="Cache-Control" content="no-transform"/>
    <meta http-equiv="Cache-Control" content="no-siteapp"/>
    <title>Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
	<meta name="description" content="">
	<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" href="/style/image/favicon.png"/>
    <link href="/style/css/highlight.min.css" rel="stylesheet">
    <link href="/style/css/style.min.css" rel="stylesheet">
	<link rel="stylesheet" href="/style/css/iconfont/iconfont.css">
	
	  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
	
</head>

<body class="bg-grey" gtools_scp_screen_capture_injected="true">

    <header id="header" class="header bg-white">
    <div class="navbar-container">
        <a href="/" class="navbar-logo">
            <img src="/style/image/logo.png" alt="ARa's DevBlog" />
            <span>ARa's DevBlog</span>
        </a>
        <div class="navbar-menu">
            <a href="/archives">Archives</a>
            <a href="/about">About</a>
        </div>
        <div class="navbar-mobile-menu" onclick="">
            <span class="icon-menu cross"><span class="middle"></span></span>
            <ul>
                <li><a href="/archives">Archives</a></li>
                <li><a href="/about">About</a></li>
            </ul>
        </div>
    </div>
</header>

    <article class="main-content page-page" itemscope itemtype="http://schema.org/Article">
    <div class="post-header">
        <h1 class="post-title" itemprop="name headline">
            Very Deep Convolutional Networks for Large-Scale Image Recognition
        </h1>
        <div class="post-data">
            <time itemprop="datePublished">Jan 25, 2021</time>
        </div>
    </div>
</article>
<div class="main-container">
    <div class="post-container">
        <div class="navigation" id="navigation">
            <h1>Contents</h1>
            <div class="nav sidenav">
	    </div>
        </div>
        <article class="post-content">
            <ul id="markdown-toc">
  <li><a href="#abstact" id="markdown-toc-abstact">Abstact</a></li>
  <li><a href="#1-introduction" id="markdown-toc-1-introduction">1. Introduction</a></li>
  <li><a href="#2-convnet-configurations" id="markdown-toc-2-convnet-configurations">2. ConvNet Configurations</a>    <ul>
      <li><a href="#21-architecture" id="markdown-toc-21-architecture">2.1 Architecture</a></li>
      <li><a href="#22-confiurations" id="markdown-toc-22-confiurations">2.2 Confiurations</a></li>
      <li><a href="#23-discussion" id="markdown-toc-23-discussion">2.3 Discussion</a></li>
    </ul>
  </li>
  <li><a href="#3-classification-framework" id="markdown-toc-3-classification-framework">3. Classification Framework</a>    <ul>
      <li><a href="#31-training" id="markdown-toc-31-training">3.1 Training</a></li>
      <li><a href="#32-testing" id="markdown-toc-32-testing">3.2 <strong>Testing</strong></a></li>
    </ul>
  </li>
</ul>

<p><span style="font-size:13pt">Karen Simonyan, Andrew Zisserman</span></p>

<h1 id="abstact">Abstact</h1>

<ul>
  <li><strong>ë³¸ ë…¼ë¬¸ì—ì„œëŠ” large-scale image recognition settingì—ì„œ CNNì˜ ê¹Šì´ê°€ accuarcyì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ê´€í•œ ì—°êµ¬ ì§„í–‰</strong></li>
  <li><strong>ì£¼ìš” ê¸°ì—¬</strong>: ë§¤ì£¼ ì‘ì€ (3x3) convolution filterë¥¼ ì‚¬ìš©í•´ì„œ ê¹Šì´ë¥¼ ì¦ê°€ì‹œí‚¤ë©´ì„œ networkë¥¼ í‰ê°€ (16-19 weight layerë¥¼ ìŒ“ì•„ì„œ ì´ì „ ë³´ë‹¤ ìƒë‹¹íˆ ê°œì„ í•¨)</li>
  <li>ë‹¤ë¥¸ ë°ì´í„° ì…‹ì—ì„œë„ ì¼ë°˜í™”ë˜ì–´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆì—ˆê³ , ë‘ ê°€ì§€ ìµœê³  ì„±ëŠ¥ì˜ ConvNet ëª¨ë¸ì„ ê³µê°œ</li>
</ul>

<h1 id="1-introduction">1. Introduction</h1>

<ul>
  <li>Convolutional Networks (ConvNets)ì€ ìµœê·¼ large-scale ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ì¸ì‹ì—ì„œ ì•„ì£¼ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„
    <ul>
      <li>deep ConvNets(2012)ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì—¬ëŸ¬ ì‹œë„ë¥¼ ì§„í–‰
        <ol>
          <li>ì²« ë²ˆì§¸ convolutional layerì˜ stridì™€ window sizeë¥¼ ë” ì‘ê²Œ ì‚¬ìš©í•˜ëŠ” ê²ƒ(2013)</li>
          <li>ì „ì²´ ì´ë¯¸ì§€ì™€ ì—¬ëŸ¬  í¬ê¸°ì— ê±¸ì³ ì¡°ë°€í•˜ê²Œ networkë¥¼ í›ˆë ¨í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒ(2014)</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ConvNet architecture ì„¤ê³„ì˜ ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ì¸¡ë©´ì¸ â€œ<strong>ê¹Šì´, depth</strong>â€œì— ëŒ€í•´ ë‹¤ë£¸
    <ul>
      <li>ì´ë¥¼ ìœ„í•´ <strong>ëª¨ë“  layerì—ì„œ (3x3)ì˜ ë§¤ì£¼ ì‘ì€ convolution filterë¥¼ ì‚¬ìš©</strong>í•˜ì—¬ networkì˜ ê¹Šì´ë¥¼ ê³„ì† ì¦ê°€ì‹œí‚´
  â€” parameter ìˆ˜ë¥¼ ì¤„ì„ìœ¼ë¡œì¨ ì¼ë°˜í™”ê°€ ë” ìš©ì´, overfittingì„ ë§‰ê³ , ì—°ì‚°ëŸ‰ì„ ì¤„ì„</li>
      <li>ê²°ê³¼ì ìœ¼ë¡œ classificationê³¼ <strong>localisation tasks</strong>ì— ëŒ€í•œ ê°€ì¥ ì¢‹ì€ ì •í™•ë„ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ ì¸ì‹ ë°ì´í„° ì…‹ì—ë„ ì ìš©í•  ìˆ˜ ìˆëŠ” í›¨ì”¬ ë” ì •í™•í•œ ConvNet architectureë¥¼ ê°œë°œ</li>
    </ul>
  </li>
</ul>

<p><strong>localisation tasks</strong>
objectê°€ ìˆëŠ” ìœ„ì¹˜ë¥¼ ì°¾ì•„ ê·¸ ì£¼ìœ„ì— bounding boxë¥¼ ê·¸ë¦¬ëŠ” ê²ƒ</p>

<p>â“â“â“</p>

<p><strong>large public image repositories</strong>
ê¸°ì¡´ì—ëŠ” ì´ë¯¸ì§€ ë§ì§€ ì•Šì•„ì„œ í›ˆë ¨ì´ í¬ê²Œ, ë§ì´ í•  ìˆ˜ ì—†ì—ˆëŠ”ë° ImageNet(image database)ê³¼ ê°™ì€ ì €ì¥ì†Œê°€ ìƒê²¨ì„œ ì´ëŸ¬í•œ ë¬¸ì œì ì„ í•´ê²°í•  ìˆ˜ ìˆì—ˆìŒ
<strong>high-dimensional shallow feature</strong>
ë†’ì€ ì°¨ì›ì˜ ë°ì´í„°ë¥¼ í•™ìŠµ ê³„ì¸µì„ ì ê²Œ ì‚¬ìš©í•´ì„œë„ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í–ˆë‹¤? â€” ë”¥ëŸ¬ë‹ì´ ìœ í–‰í•˜ê¸° ì „ì—ëŠ” ìë™ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼, í•„í„°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì†ìœ¼ë¡œ ë§Œë“¤ì–´ ì‚¬ìš©í–ˆëŠ”ë° ìƒëŒ€ì ìœ¼ë¡œ dimensionì´ í¬ê³  ë³µì¡í•œë° ì˜ˆì „ ëª¨ë¸ì„ ì¼ì»«ëŠ” ê²ƒ ê°™ìŒ</p>

<p><strong>testbed</strong>
imageë¥¼ í™œìš©í•´ì„œ ë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” ë¬¸ì œë‚˜ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì¥ì†Œ</p>

<p><strong>used as a part of a relatively simple pipelines</strong></p>

<p>ë‹¤ë¥¸ ëª¨ë¸ê³¼ í•©ì³ì„œ ì‚¬ìš©í•  ë•Œ ì•ë‹¨ì— ë§ì´ ì‚¬ìš©ë¨</p>

<h1 id="2-convnet-configurations">2. ConvNet Configurations</h1>

<h3 id="21-architecture">2.1 Architecture</h3>

<blockquote>
  <p><strong>Conv layer</strong></p>
</blockquote>

<ul>
  <li><strong>feature extractor</strong></li>
  <li>input: fixed-size 224x224 RGB (preprocessing: ê° channelì— ëŒ€í•´ meanë¹¼ëŠ” ê²ƒ â€” data centering)
    <ul>
      <li>ìŒìˆ˜~ì–‘ìˆ˜ë¡œ ê°’ì˜ ë²”ìœ„ë¥¼ ë§ì¶¤</li>
    </ul>
  </li>
  <li>(3x3) filterë¥¼ ì‚¬ìš©í•˜ëŠ” convolutional layerë¥¼ ìŒ“ì€ êµ¬ì¡°
    <ul>
      <li>3x3 filter: ìœ„/ì•„ë˜, ì™¼ìª½/ì˜¤ë¥¸ìª½, ì¤‘ì•™ì˜ ì •ë³´ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í¬ê¸°</li>
    </ul>
  </li>
  <li>1x1 convolution filterë„ ì‚¬ìš©
    <ul>
      <li>input channelsì˜ linear transformationì„ ìœ„í•´</li>
    </ul>
  </li>
  <li>stride: 1, padding ì ìš© O</li>
</ul>

<blockquote>
  <p><strong>Spatial Pooling layer</strong></p>
</blockquote>

<ul>
  <li>conv layer ì´í›„ ì ìš© (ëª¨ë“  conv ì´í›„ì— ì‚¬ìš©ë˜ì§€ëŠ” ì•ŠìŒ)</li>
  <li>ì´ 5ê°œì˜ max poolinhg layer ì‚¬ìš©
    <ul>
      <li>2x2 size, stride: 2</li>
    </ul>
  </li>
</ul>

<p>â“â“â“</p>

<p><strong>Spatial Pooling layer = Spatial Pyramid Pooling? No!</strong></p>

<p><del>ë§Œì•½ ë‘ê°œê°€ ê°™ë‹¤ë©´ ì´ë¯¸ì§€ ì¸ì‹ì—ì„œ ì¼ì •í•œ í¬ê¸°ë¡œ ìë¥´ê±°ë‚˜ ì¶•ì†Œí•´ì„œ ëª¨ë¸ì— ë„£ì€ê²Œ ì•„ë‹ˆë¼ í†µì±„ë¡œ ë„£ê³  poolingì„ ì´ìš©í•´ì„œ ì¼ì •í•œ í¬ê¸°ë¡œ ë§ì¶”ì„œ FC ì…ë ¥ìœ¼ë¡œ ë„£ëŠ” ê²ƒ ê°™ì€ë° ë’¤ì—ì„œ í›ˆë ¨í•  ë•Œ íŠ¹ì • ì°¨ì›ìœ¼ë¡œ ë§ì¶”ëŠ” ê²ƒ ê°™ì€ë° ì™œ ì´ ë°©ë²•ì€ ì‚¬ìš©í•˜ëŠ” ê²ƒì¸ì§€?</del></p>

<p>â†’ 10x10ì´ ìˆìœ¼ë©´ ì´ê±¸ ì¤„ì—¬ì„œ strideì— ë§ì¶° 5x5ë¡œ ì¤„ì´ëŠ” ê²ƒ (ì¼ë°˜ì ì¸ poolingì´ë‘ ê°™ìŒ)</p>

<blockquote>
  <p><strong>Fully-connected layer (FC)</strong></p>
</blockquote>

<ul>
  <li><strong>convì—ì„œ ë‚˜ì˜¨ featureë¡œ í™•ë¥ ê°’ì„ ì´ìš©í•´ classification</strong></li>
  <li>3ê°œì˜ FC ì‚¬ìš© + softmax layer
    <ul>
      <li>1-2 layer: 4096ê°œ node, 3 layer: 1000 (classificationì„ ìœ„í•´)</li>
    </ul>
  </li>
  <li>activation function: ReLU</li>
  <li>Local Response Normalization (LRN) ì •ê·œí™” í¬í•¨X (í•˜ë‚˜ ì œì™¸í•˜ê³ )
    <ul>
      <li>ReLUë¥¼ ì‚¬ìš©í•˜ë©´ ì–‘ìˆ˜ê°’ì€ ìê¸° ìì‹ ì´ ë‚˜ì˜¤ê²Œ ë˜ì–´, ë§¤ìš° í° ê°’ì„ ê°–ëŠ” ê²½ìš°(outlier) ë‹¤ë¥¸ ê°’ë“¤ì´ ê¸°ëŠ¥ì„ ëª»í•  ìˆ˜ ìˆìŒ</li>
      <li>ReLU ì´í›„ì— ë‚˜ì˜¤ëŠ” ê°’ì„ ì£¼ë³€ ê°’ì„ ì´ìš©í•´ normalizeí•´ì¤Œìœ¼ë¡œì¨ ì´ëŸ¬í•œ ê²ƒì„ ì™„í™”</li>
    </ul>
  </li>
</ul>

<h3 id="22-confiurations">2.2 Confiurations</h3>

<ul>
  <li>ê¹Šì´ê°€ ë” ê¹Šì–´ì§ì—ë„ ë¶ˆêµ¬í•˜ê³  ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” networkì— ìˆëŠ” ê°€ì¤‘ì¹˜ì˜ ìˆ˜ëŠ” ë” ì–•ê³  í° convë¥¼ ê°–ëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ìˆ˜ë³´ë‹¤ í¬ì§€ ì•ŠìŒ
    <ul>
      <li>Sermanet et al., 2014: 144M weights</li>
    </ul>
  </li>
</ul>

<center><img src="https://user-images.githubusercontent.com/46676700/124697233-67018600-df21-11eb-86c6-962f45358b86.png" alt="img" style="zoom: 80%;" /></center>

<h3 id="23-discussion">2.3 Discussion</h3>

<blockquote>
  <p><strong>ì°¨ë³„ì </strong></p>
</blockquote>

<ul>
  <li>stride=4 11x11 filter, stride=2 7x7 filterì™€ ê°™ì´ í° filterë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ì „ ëª¨ë¸ë“¤ê³¼ ë‹¬ë¦¬ <strong>3x3ì˜ ë§¤ìš° ì‘ì€ sizeì˜ filterë¥¼ ì‚¬ìš©</strong></li>
</ul>

<blockquote>
  <p><strong>3x3 filterë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ </strong></p>
</blockquote>

<p>Table1ì—ì„œ ì¤‘ê°„ì— spatial poolingì´ ì—†ëŠ” ê²½ìš° ì—¬ëŸ¬ ê°œì˜ convê°€ stackë˜ì–´ ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ</p>

<ul>
  <li>2ê°œë¥¼ ì‚¬ìš©í•˜ê²Œë˜ë©´ 5x5 filterë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ (= effective receptive fieldê°€ ê°™ìŒ)
    <ul>
      <li>3ê°œ ì‚¬ìš©: 7x7</li>
    </ul>
  </li>
</ul>

<p><strong>â†’ ì–»ëŠ” ì´ì ì€?</strong></p>

<ol>
  <li>activation functionì„ ë” ë§ì´ ê±°ì¹˜ë©´ì„œ non-linearí•œ ë¬¸ì œë¥¼ ë” ì˜ í’€ ìˆ˜ ìˆê²Œ ë¨</li>
  <li>parameterì˜ ìˆ˜ë¥¼ ì¤„ì„
    <ul>
      <li>Cì±„ë„ì˜ 3x3 convolutionì´ 3 layerì¸ ê²½ìš°: $3(3^2C^2) = 27C^2$</li>
      <li>Cì±„ë„ 7x7 convolutionì´ 1 layerì¸ ê²½ìš°: $7^2(C^2)=49C^2$</li>
    </ul>
  </li>
</ol>

<ul>
  <li>decision functionì˜ ë¹„ì„ í˜•ì„±ì„ ì¦ê°€ì‹œí‚¤ê¸° ìœ„í•´ 1x1 convë¥¼ ì‚¬ìš©
â€” ë¹„ì„ í˜•ì„±ì„ ì¦ê°€ì‹œí‚¤ë©´ ì¢€ ë” ë³µì¡í•œ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆê²Œ ë¨</li>
</ul>

<blockquote>
  <p><strong>ìœ ì‚¬í•œ task</strong></p>
</blockquote>

<ul>
  <li>
    <p>Lin et al.(2014)
â€” â€œNetwork in Networkâ€ì—ì„œ 1x1 convê°€ í™œìš©ë¨, ê·¸ëŸ¬ë‚˜ ë³¸ ë…¼ë¬¸ì˜ êµ¬ì¡°ë³´ë‹¤ ê¹Šì§€ ì•Šìœ¼ë©° ILSVRC ë°ì´í„° ì…‹ì—ì„œ í‰ê°€í•˜ì§€ ì•ŠìŒ</p>
  </li>
  <li>
    <p>Goodfellow et al.(2014)
â€” ê±°ë¦¬ ë²ˆí˜¸ ì¸ì‹ì—ì„œ ê¹Šì€ ConvNetsì„ ì ìš©í–ˆê³  ê¹Šì´ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì„±ëŠ¥ì´ í–¥ìƒë¨ì„ ë³´ì—¬ì¤Œ</p>
  </li>
  <li>
    <p>Szegedy et al.(2014)
â€”â€GoogLeNetâ€ ë§¤ìš° ê¹Šì€ ConvNet(22 layer)ì™€ ì‘ì€ convolutionì„ ê¸°ë°˜í•œë‹¤ëŠ” ì ì—ì„œ ìœ ì‚¬í•¨ (1x1, 5x5 ì‚¬ìš©), ë³¸ ë…¼ë¬¸ë³´ë‹¤ network topologyê°€ ë³µì¡í•˜ê³  ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ ë¶„ë¥˜ì—ì„œ ë³¸ ë…¼ë¬¸ ì„±ëŠ¥ì´ ë” ìš°ìˆ˜</p>
  </li>
</ul>

<h1 id="3-classification-framework">3. Classification Framework</h1>

<h3 id="31-training">3.1 Training</h3>

<blockquote>
  <p><strong>hyperparameter</strong></p>
</blockquote>

<ul>
  <li>cost function: Cross Entropy</li>
  <li>mini-batch size: 256</li>
  <li>optimizer: Momentum=0.9</li>
  <li>regularization: L2 regularization($5 Â· 10^{âˆ’4}$), Dropout(0.5)</li>
  <li>learning rate: $10^{-2}$ (validation accuarcyì˜ ì¦ê°€ê°€ ë©ˆì¶”ë©´ 0.1ì”© ê°ì†Œ â€” 3ë°° ê°ì†Œ)</li>
  <li>370L iterations (74 epochs)</li>
  <li>pre-initialization: A modelì˜ ì¼ë¶€(ì²˜ìŒ 4ê°œ conv+ë§ˆì§€ë§‰ 3ê°œ FC)ë¥¼ í›ˆë ¨í•œ ë’¤ ê°€ì ¸ì™€ì„œ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©</li>
</ul>

<blockquote>
  <p><strong>Training image size</strong></p>
</blockquote>

<p><strong>isotropically-rescaled</strong></p>

<ul>
  <li>imageë¥¼ VGG model input size(224x224)ì— ë§ë„ë¡ ë³€ê²½í•´ì¤˜ì•¼ í•¨</li>
  <li><strong>Së¥¼ ì´ìš©</strong>í•´ì„œ <strong>ë¹„ìœ¨ì€ ê·¸ëŒ€ë¡œ</strong> ë‘ê³  sizeë¥¼ ë°”ê¾¼ ë’¤ <strong>cropí•˜ì—¬ ì‚¬ìš©</strong></li>
</ul>

<p><strong>training scale S</strong></p>

<ol>
  <li>Së¥¼ ê³ ì •ì‹œí‚¤ëŠ” ê²ƒ
    <ul>
      <li>S=256ìœ¼ë¡œ ë‘ì–´ ë¨¼ì € networkë¥¼ í›ˆë ¨í•˜ê³ , S=384ë¡œ í›ˆë ¨í•  ë•ŒëŠ” 256ìœ¼ë¡œ í›ˆë ¨í•œ íŒŒë¼ë¯¸í„°ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ì‚¬ìš©í•˜ê³ , ë” ì‘ì€ learning rate ì‚¬ìš© ($10^{-3}$)</li>
    </ul>
  </li>
  <li>256~512 ì¤‘ randomí•˜ê²Œ Sê°’ ì‚¬ìš© (multi-scale)
    <ul>
      <li>objectê°€ ëª¨ë‘ ë‹¤ë¥¸ sizeë¥¼ ê°–ìœ¼ë©´ì„œ í•™ìŠµíš¨ê³¼ê°€ ë” ì¢‹ì•„ì§ˆ ìˆ˜ ìˆìŒ</li>
      <li>data augmentation íš¨ê³¼(= scale jittering)</li>
    </ul>
  </li>
</ol>

<h3 id="32-testing">3.2 <strong>Testing</strong></h3>

<p>trainì— ì‚¬ìš©ëœ Sì™€ ê°™ì€ ì—­í• ì„ í•˜ëŠ” <strong>Q</strong> ë¥¼ ì‚¬ìš©í•˜ì—¬ <strong>image rescaling</strong> ì ìš©</p>

<ul>
  <li>$Q \ne S$</li>
</ul>

<p><strong>êµ¬ì¡° ë³€ê²½</strong> (cropí•˜ì§€ ì•Šì€ ì „ì²´ ì´ë¯¸ì§€ì— ì ìš©í•  ìˆ˜ ìˆìŒ)</p>

<ul>
  <li>FC layer â†’ conv
    <ul>
      <li>first: <strong>7x7 conv</strong></li>
      <li>last two: <strong>1x1 conv</strong></li>
    </ul>
  </li>
</ul>

<p>â†’ class ìˆ˜ì™€ ë™ì¼í•œ channel ìˆ˜ì™€ input image sizeì— ë”°ë¼ ê°€ë³€ ê³µê°„ í•´ìƒë„ë¥¼ ê°–ëŠ” class score map</p>

<p><strong>ê³ ì • í¬ê¸°ì˜ ë²¡í„°</strong></p>

<ul>
  <li>class scoreë¥¼ ì–»ê¸° ìœ„í•´ pooling ì§„í–‰(spatially averaged)</li>
  <li>imageë¥¼ ìˆ˜í‰ìœ¼ë¡œ ë’¤ì§‘ì–´ì„œ, ì›ë³¸ ì´ë¯¸ì§€ì™€ ë’¤ì§‘íŒ ì´ë¯¸ì§€ì˜ softmax ê²°ê³¼ë¥¼ í‰ê· ë‚´ ìµœì¢… scoreë¡œ ì‚¬ìš©</li>
</ul>

<hr />

<p><strong>Reference</strong></p>

<ul>
  <li>paper [<a href="https://arxiv.org/pdf/1409.1556.pdf">ğŸ“‘</a>]</li>
  <li>CNNì˜ parameter ê°œìˆ˜ì™€ tensor ì‚¬ì´ì¦ˆ ê³„ì‚°í•˜ê¸° [<a href="https://seongkyun.github.io/study/2019/01/25/num_of_parameters/">ğŸ‘†</a>]</li>
</ul>

        </article>
        <div class="post-content">
         <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<div id="gitalk-container"></div>

<script data-no-instant type="text/javascript">
const gitalk = new Gitalk({
  clientID: '5304ae17c5ba0ce3b2aa',
  clientSecret: '22801b52c86101ff074072faa1631475954d2936',
  repo: 'arabae.github.io',
  owner: 'arabae',
  admin: ['arabae'],
  id: location.pathname,      // Ensure uniqueness and length less than 50
  distractionFreeMode: true  // Facebook-like distraction free mode
})

gitalk.render('gitalk-container')
</script>
        </div>
    </div>
</div>

    
    <footer id="footer" class="footer bg-white">
    <div class="footer-social">
        <div class="footer-container clearfix">
            <div class="social-list">
		<a href="/"><span class='iconfont icon-home'></span>&nbsp;&nbsp;HOME</a>
                <a rel="nofollow" target="_blank" href="https://github.com/arabae"><span class='iconfont icon-github'></span>&nbsp;&nbsp;Github</a>
                <a target="_blank" href="/feed.xml"><span class='iconfont icon-rss'></span>&nbsp;&nbsp;RSS</a>
            </div>
        </div>
    </div>
    <div class="footer-meta">
        <div class="footer-container">
            <div class="meta-item meta-copyright">
                <div class="meta-copyright-info">
                    <a href="https://github.com/arabae" class="info-logo">
                        <img src="/style/image/logo.png" alt="wonder">
                    </a>
                    <div class="info-text">
                        <p>Copyright &copy; 2021 - 2021 <a href="https://github.com/arabae"><code>ARa Bae</code></a></p>
                        <p>Powered by <a href="http://jekyllrb.com" target="_blank" rel="nofollow"><code>jekyll</code></a>ï¼Œtheme is <a href="https://github.com/lightfish-zhang/pinghsu-jekyll" target="_blank" rel="nofollow"><code>pinghsu</code></a></p>
                    </div>
                </div>
            </div>

            <div class="meta-item meta-posts">
                <h3 class="meta-title">RECENT POSTS</h3>
                
                    <li>
                        <a href="/2021-08-03-Conformer">Conformer: Convolution-augmented Transformer for Speech Recognition</a>
                    </li>
                
                    <li>
                        <a href="/2021-01-25-Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recognition">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>
                    </li>
                
                    <li>
                        <a href="/2020-10-13-Cross-Attentive-Pooling-for-SV">Cross attentive pooling for speaker verification</a>
                    </li>
                
                    <li>
                        <a href="/2020-10-06-Metric-Laerning-for-Keyword-Spotting">Metric Learning for Keyword Spotting</a>
                    </li>
                
                    <li>
                        <a href="/2019-07-30-Attention-based-models-for-TDSV">Attention-based Models For Text-dependent Speaker Verification</a>
                    </li>
                
                    <li>
                        <a href="/2019-07-24-TISV-with-Adversarial-Learning-on-Short-Utterances">Text-Independent Speaker Verification with Adversarial Learning on Short Utterances</a>
                    </li>
                
                    <li>
                        <a href="/2019-07-10-GE2E-loss-for-SV">Generalized End to End Loss For Speaker Verification</a>
                    </li>
                
            </div>

        </div>
    </div>
</footer>

<!-- #end -->
<script src="//cdn.bootcss.com/jquery/1.10.1/jquery.min.js"></script>
<script>
	!window.jQuery && document.write(unescape('%3Cscript src="/style/js/jquery.min.js"%3E%3C/script%3E'))
</script>
<script src="/style/js/headroom.min.js"></script>
<script src="/style/js/nav.min.js"></script>
<script type="text/javascript">
    var header = new Headroom(document.getElementById("header"), {
        tolerance: 10,
        offset : 80,
        classes: {
            initial: "animated",
            pinned: "slideDown",
            unpinned: "slideUp"
        }
    });
    header.init();
</script>

<script>window.SmoothScrollOptions = { stepSize: 36 }</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/smoothscroll/1.4.8/SmoothScroll.min.js"></script>
<script>
	!window.SmoothScroll && document.write(unescape('%3Cscript src="/style/js/SmoothScroll.min.js"%3E%3C/script%3E'))
</script>




  </body>
</html>
