<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta http-equiv="Cache-Control" content="no-transform"/>
    <meta http-equiv="Cache-Control" content="no-siteapp"/>
    <title>Attentive Statistics Pooling for Deep Speaker Embedding</title>
	<meta name="description" content="">
	<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" href="/style/image/favicon.png"/>
    <link href="/style/css/highlight.min.css" rel="stylesheet">
    <link href="/style/css/style.min.css" rel="stylesheet">
	<link rel="stylesheet" href="/style/css/iconfont/iconfont.css">
	
	  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
	
</head>

<body class="bg-grey" gtools_scp_screen_capture_injected="true">

    <header id="header" class="header bg-white">
    <div class="navbar-container">
        <a href="/" class="navbar-logo">
            <img src="/style/image/logo.png" alt="ARa's DevBlog" />
            <span>ARa's DevBlog</span>
        </a>
        <div class="navbar-menu">
            <a href="/archives">Archives</a>
            <a href="/about">About</a>
        </div>
        <div class="navbar-mobile-menu" onclick="">
            <span class="icon-menu cross"><span class="middle"></span></span>
            <ul>
                <li><a href="/archives">Archives</a></li>
                <li><a href="/about">About</a></li>
            </ul>
        </div>
    </div>
</header>

    <article class="main-content page-page" itemscope itemtype="http://schema.org/Article">
    <div class="post-header">
        <h1 class="post-title" itemprop="name headline">
            Attentive Statistics Pooling for Deep Speaker Embedding
        </h1>
        <div class="post-data">
            <time itemprop="datePublished">May 01, 2019</time>
        </div>
    </div>
</article>
<div class="main-container">
    <div class="post-container">
        <div class="navigation" id="navigation">
            <h1>Contents</h1>
            <div class="nav sidenav">
	    </div>
        </div>
        <article class="post-content">
            <ul id="markdown-toc">
  <li><a href="#-abstract" id="markdown-toc--abstract">ğŸ“Œ <strong>Abstract</strong></a></li>
  <li><a href="#-introduction" id="markdown-toc--introduction">ğŸ“Œ <strong>Introduction</strong></a></li>
  <li><a href="#-deep-speaker-embedding" id="markdown-toc--deep-speaker-embedding">ğŸ“Œ <strong>Deep speaker embedding</strong></a></li>
  <li><a href="#-high-order-pooling-with-attention" id="markdown-toc--high-order-pooling-with-attention">ğŸ“Œ <strong>High-order pooling with attention</strong></a></li>
  <li><a href="#-experimental-settings" id="markdown-toc--experimental-settings">ğŸ“Œ <strong>Experimental settings</strong></a></li>
</ul>

<p><span style="font-size:13pt">Koji Okabe, Takafumi Koshinaka, Koichi Shinoda</span></p>

<h1 id="-abstract">ğŸ“Œ <strong>Abstract</strong></h1>
<ul>
  <li>
    <p><span style="background-color:#FFE49B"><strong>Text-independent</strong>(ë¬¸ì¥ ë…ë¦½ : ë°œí™” ë‚´ìš©ì´ ë™ì¼í•˜ì§€ í•˜ì§€ ì•ŠìŒ)í•œ <strong>Speaker Verification</strong>(í™”ì ê²€ì¦ : ë“±ë¡ëœ í™”ìì¸ì§€ ì•„ë‹Œì§€ íŒë‹¨, SV)ì—ì„œ <strong>Deep speaker embeddingì„ ìœ„í•œ attentive statistics pooling</strong> ì œì•ˆ</span></p>
  </li>
  <li>
    <p>ê¸°ì¡´ì˜ speaker embeddingì—ì„œëŠ” ë‹¨ì¼ ë°œí™”ì˜ ëª¨ë“  frameì—ì„œ frame-levelì˜ íŠ¹ì§•ì„ ëª¨ë‘ í‰ê·  ë‚´ì–´ utterance-levelì˜ íŠ¹ì§•ì„ í˜•ì„±</p>
  </li>
  <li>
    <p>ì œì•ˆí•˜ëŠ” ë°©ë²•ì€ attention mechanismì„ ì‚¬ìš©í•˜ì—¬ ê° frameë§ˆë‹¤ ë‹¤ë¥¸ weight(ê°€ì¤‘ì¹˜)ë¥¼ ë¶€ì—¬í•˜ê³ , weighted mean(ê°€ì¤‘ í‰ê· )ê³¼ weighted standard deviations(ê°€ì¤‘ í‘œì¤€ í¸ì°¨)ë¥¼ ìƒì„±</p>
  </li>
</ul>

<p>âœ”  <span style="background-color:#FFE49B">NISE SRE 2012 ë° VoxCeleb data setì—ì„œ ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ EERì´ ê°ê° 7.5%, 8.1% ê°ì†Œ</span></p>

<p><br /></p>

<hr />

<p><br /></p>

<h1 id="-introduction">ğŸ“Œ <strong>Introduction</strong></h1>

<ul>
  <li>
    <p><strong>í™”ì ì¸ì‹ì€ ì§€ë‚œ 10ë…„ë™ì•ˆ i-vector paradigmê³¼ ì§„í™”</strong>í•˜ì˜€ê³ , i-vectorëŠ” ê³ ì •ëœ ì €ì°¨ì›ì˜ íŠ¹ì§• ë²¡í„° í˜•íƒœë¡œ ìŒì„± ë°œí™” í˜¹ì€ í™”ìë¥¼ í‘œí˜„</p>
  </li>
  <li>
    <p>ë‹¤ì–‘í•œ ê¸°ê³„í•™ìŠµì„ í†µí•´ Deep learningì´ ì„±ëŠ¥ í–¥ìƒì— í¬ê²Œ ê¸°ì—¬í•˜ë©°, í™”ì ì¸ì‹ì„ ìœ„í•œ íŠ¹ì§• ì¶”ì¶œì— Deep learningì„ ë„ì…ì´ ì¦ê°€</p>
  </li>
  <li>
    <p>ì´ˆê¸° ì—°êµ¬ì—ì„œëŠ” ASR(Automatic Speech Recognition)ì˜ ìŒí–¥ ëª¨ë¸ì—ì„œ ë„ì¶œëœ DNNì„ UBMìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ì˜ GMMê¸°ë°˜ UBMë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ì§€ë§Œ ì–¸ì–´ ì˜ì¡´ì„± ë‹¨ì ê³¼ í›ˆë ¨ì„ ìœ„í•´ ìŒì†Œ transcriptionì´ í•„ìš”</p>
  </li>
  <li>
    <p>ìµœê·¼ <strong>DNNì€ ì´ëŸ¬í•œ i-vector frameworkì™€ ë…ë¦½ì </strong>ìœ¼ë¡œ <strong>í™”ì ë§ˆë‹¤ ê³ ìœ í•œ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ëŠ”ë° ìœ ìš©</strong>í•˜ë‹¤ê³  ë°í˜€ì§ (íŠ¹íˆ, ì§§ì€ ë°œí™” ì¡°ê±´ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì„)</p>
  </li>
  <li>
    <p>Text-dependent(ë¬¸ì¥ ì¢…ì† : ë°œí™” ë‚´ìš©ì´ ë™ì¼í•¨) SVì—ì„œ LSTM(ë§ˆì§€ë§‰ frameì—ì„œ í•˜ë‚˜ì˜ ì¶œë ¥ì„ ê°–ëŠ” êµ¬ì¡°)ì„ ì‚¬ìš©í•˜ì—¬ utterance-levelì˜ íŠ¹ì§•ì„ ì–»ëŠ” End-to-End Neural Networkê¸°ë°˜ì˜ ë°©ë²•ì´ ì œì•ˆë˜ì—ˆìœ¼ë©°, ê¸°ì¡´ì˜ i-vectorë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„</p>
  </li>
  <li>
    <p>Text-independent SVëŠ” ì…ë ¥ìœ¼ë¡œ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ë°œí™”ë¥¼ ê°–ìœ¼ë¯€ë¡œ average pooling layerê°€ ë„ì…ë˜ì–´ frame-levelì˜ í™”ì íŠ¹ì§• ë²¡í„°ë¥¼ ì¼ì •í•œì°¨ì›ì„ ê°–ëŠ” speaker embedding ë²¡í„°ë¥¼ ì–»ìŒ</p>
  </li>
  <li>
    <p>ëŒ€ë¶€ë¶„ ìµœê·¼ ì—°êµ¬ì—ì„œ DNNì´ i-vectorë³´ë‹¤ ë” ë‚˜ì€ ì •í™•ë„ë¥¼ ê°–ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ë©° Snyder ì™¸ëŠ” average poolingë¥¼ í™•ì¥í•œ statistics pooling (í‰ê·  ë° í‘œì¤€ í¸ì°¨ ê³„ì‚°)ì„ ì±„íƒ</p>
  </li>
  <li>
    <p>ê·¸ëŸ¬ë‚˜ ì•„ì§ ì •í™•ë„ í–¥ìƒì— ëŒ€í•œ í‘œì¤€ í¸ì°¨ poolingì˜ íš¨ìœ¨ì„±ì€ ë³´ê³ í•˜ì§€ ì•ŠìŒ</p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>
    <p>ìµœê·¼ ë‹¤ë¥¸ ì—°êµ¬ì—ì„œëŠ” ì´ì „ì— ê¸°ê³„ ë²ˆì—­ì—ì„œ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì˜¨ <strong>attention mechanismê³¼ í†µí•©</strong></p>
  </li>
  <li>
    <p>í™”ì ì¸ì‹ì—ì„œë„ ì¤‘ìš”ë„ ê³„ì‚° ì‹œ, speaker embedding ì¶”ì¶œí•˜ëŠ” networkì˜ ì¼ë¶€ë¡œ ì‘ë™í•˜ëŠ” ì‘ì€ attention network ì‚¬ìš©</p>
  </li>
  <li>
    <p>ê³„ì‚°ëœ ì¤‘ìš”ë„ëŠ” frame-levelì˜ íŠ¹ì§• ë²¡í„°ì˜ weighted mean ê³„ì‚°í•  ë•Œ ì‚¬ìš©í•˜ì—¬ speaker embeddingì´ ì¤‘ìš”í•œ frameì— ì´ˆì ì„ ë§ì¶¤</p>
  </li>
  <li>
    <p>ê·¸ëŸ¬ë‚˜ ì´ì „ ì—°êµ¬ì—ì„œëŠ” ê³ ì • ê¸¸ì´ì˜ text-independent í˜¹ì€ text-dependent í™”ì ì¸ì‹ê³¼ ê°™ì€ ì œí•œëœ ì‘ì—…ì—ì„œë§Œ ìˆ˜í–‰</p>
  </li>
</ul>

<p><strong>- ë³¸ ë…¼ë¬¸ì—ì„œ attention mechanismìœ¼ë¡œ ê³„ì‚°ëœ ì¤‘ìš”ë„ë¡œ importance-weighted standard deviationê³¼ weighted meanì‚¬ìš©í•œ ìƒˆë¡œìš´ poolingë°©ë²•ì¸ attentive statistics poolingë¥¼ ì œì•ˆ</strong></p>

<ul>
  <li>ê°€ë³€ ê¸¸ì´ì˜ text-independentí•œ í™˜ê²½ì—ì„œ attentive statisitics poolingì„ ì‚¬ìš©í•˜ëŠ” ì²« ë²ˆì§¸ ì‹œë„ ì´ë©°, ë‹¤ì–‘í•œ pooling layer ë¹„êµë¥¼ í†µí•´ í‘œì¤€ í¸ì°¨ê°€ í™”ì íŠ¹ì„±ì— ë¯¸ì¹˜ëŠ” íš¨ê³¼ë¥¼ ì‹¤í—˜ì ìœ¼ë¡œ ë³´ì—¬ì¤Œ</li>
</ul>

<p><br /></p>

<hr />

<p><br /></p>

<h1 id="-deep-speaker-embedding">ğŸ“Œ <strong>Deep speaker embedding</strong></h1>

<ul>
  <li>ê¸°ì¡´ì˜ DNNì„ ì‚¬ìš©í•œ speaker embedding ì¶”ì¶œ ë°©ë²•</li>
</ul>

<blockquote>
  <p>input : acoustic feature (MFCC, filter-bank ë“±)<br />
frame-levelì˜ íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•´ TDNN, CNN, LSTM ë“±ì˜ Neural Network<br />
ê°€ë³€ ê¸¸ì´ì˜ frame-level íŠ¹ì§•ì„ ê³ ì • ì°¨ì›ì˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ pooling layer<br />
utterance-levelì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ fully-connected layer(hidden layer ì¤‘ í•˜ë‚˜ì˜ node ìˆ˜ë¥¼ ì‘ê²Œ í•˜ì—¬ bottleneck featureë¡œ ì‚¬ìš©)</p>
</blockquote>

<p><br /></p>

<center><img src="https://user-images.githubusercontent.com/46676700/89165519-a443f200-d5b3-11ea-8009-d34a68859aa4.png" alt="img" style="zoom:60%;" /></center>

<p><br /></p>

<hr />

<p><br /></p>

<h1 id="-high-order-pooling-with-attention">ğŸ“Œ <strong>High-order pooling with attention</strong></h1>

<p>&lt; Statistics pooling - ê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ pooling ë°©ë²• &gt;</p>

<ul>
  <li>frame-level íŠ¹ì§•ì— ëŒ€í•´ í‰ê· (mean)ê³¼ í‘œì¤€ í¸ì°¨(standard deviation) ê³„ì‚° (âŠ™ : Hadamard ê³±)í•˜ì—¬ concatenation</li>
</ul>

<center><img src="https://user-images.githubusercontent.com/46676700/89165568-b160e100-d5b3-11ea-9a93-2a31b6530b2b.png" alt="img" style="zoom: 45%;" /></center>

<p>&lt; Attention mechanism &gt;</p>

<ul>
  <li>ê¸°ê³„ ë²ˆì—­ì—ì„œ ê¸´ ë¬¸ì¥ì˜ ì„±ëŠ¥ ì €í•˜ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ëª¨ë¸ì´ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ë•Œ <strong>íŠ¹ì • ë‹¨ì–´ë¥¼ ì§‘ì¤‘</strong>í•´ì„œ ë³´ëŠ” ë°©ë²•ì„ ë„ì…</li>
</ul>

<center><img src="https://user-images.githubusercontent.com/46676700/89165571-b1f97780-d5b3-11ea-91e3-8fa3f49000fc.png" alt="img" style="zoom: 80%;" /><img src="https://user-images.githubusercontent.com/46676700/89165573-b1f97780-d5b3-11ea-9545-3a591f97f98d.png" alt="img" style="zoom: 50%;" /></center>

<p><br /></p>

<p><img src="https://user-images.githubusercontent.com/46676700/89165553-aefe8700-d5b3-11ea-9e0a-c4c8d5fc14a0.png" alt="img" /></p>

<ul>
  <li>decoderì˜ <span style="color:#a5cbf0"><strong>ì‹œê°„ i(í˜„ì¬)ì—ì„œ hidden state ë²¡í„°</strong></span>ëŠ” <span style="color:#a5cbf0"><strong>ì‹œê°„ i-1(ì´ì „)ì˜ hidden state ë²¡í„°</strong></span>ì™€ <span style="color:#ffaddf"><strong>ì‹œê°„ i-1(ì´ì „)ì—ì„œ decoderì˜ output</strong></span>, ê·¸ë¦¬ê³  <span style="color:#7cbfb6"><strong>ì‹œê°„ i(í˜„ì¬)ì—ì„œì˜ context ë²¡í„°</strong></span>ë¥¼ ì…ë ¥ìœ¼ë¡œ ê³„ì‚°</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/46676700/89165558-af971d80-d5b3-11ea-84c7-8f0478e8e680.png" alt="img" /></p>

<ul>
  <li><span style="color:#7cbfb6"><strong>context ë²¡í„°</strong></span>ëŠ” <strong>ì‹œê°„ iì—ì„œ ì…ë ¥ xì— ëŒ€í•œ ê¸¸ì´ T</strong> ì „ì²´ì— ëŒ€í•œ <strong><span style="color:#f9d877">encoder hidden state ë²¡í„°</span></strong>ì˜ <strong>ê°€ì¤‘í•©</strong>ìœ¼ë¡œ ê³„ì‚°</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/46676700/89165559-b02fb400-d5b3-11ea-9ad9-a8383a6810d6.png" alt="img" /></p>

<ul>
  <li><span style="color:#33558c"><strong>ì‹œê°„ iì—ì„œ jë²ˆì§¸ ë‹¨ì–´ì˜ energy</strong></span>ëŠ” <strong><span style="color:#a5cbf0">ì‹œê°„ i-1(ì´ì „)ì—ì„œ decoder hidden state</span></strong>ì™€<strong><span style="color:#f9d877">Â jë²ˆì§¸ encoder hidden state</span></strong>ê°€ ì…ë ¥ì¸ <strong>aligment model(a)</strong> ê²°ê³¼ê°’ (alignment modelì€ tanh, ReLU ë“± activation function)</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/46676700/89165560-b02fb400-d5b3-11ea-8753-68026664a442.png" alt="img" /></p>

<p><br /></p>

<p>&lt; Attentive statistics pooling &gt;</p>

<center><img src="https://user-images.githubusercontent.com/46676700/89165563-b0c84a80-d5b3-11ea-9590-62c129a447e4.png" alt="img" style="zoom: 50%;" /><img src="https://user-images.githubusercontent.com/46676700/89165564-b0c84a80-d5b3-11ea-8a2f-c887055c76d8.png" alt="img" style="zoom: 50%;" /></center>

<p>attention mechanismì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°í•œ <strong>ê°€ì¤‘ì¹˜ë¥¼ í†µí•´ meanê³¼ standard deviationì„ ê°±ì‹ </strong></p>

<center><img src="https://user-images.githubusercontent.com/46676700/89165566-b160e100-d5b3-11ea-9625-41ccb0db4353.png" alt="img" style="zoom: 67%;" /></center>

<p><br /></p>

<hr />

<p><br /></p>

<h1 id="-experimental-settings">ğŸ“Œ <strong>Experimental settings</strong></h1>

<p><strong>i-vector</strong></p>

<blockquote>
  <p>input : 60ì°¨ì› MFCC<br />
UBM : 2048 mixture<br />
TV matrix, i-vector : 400ì°¨ì›<br />
Similarity score : PLDA</p>
</blockquote>

<p><br /></p>

<p><strong>Deep speaker embedding</strong></p>

<blockquote>
  <p>input : 20ì°¨ì›(SRE 12), 40ì°¨ì›(VoxCeleb) MFCC<br />
hidden layer : 5-layer TDNN(activation function : ReLU, node : 512)<br />
pooling dimension : 1500ì°¨ì›<br />
acoustic feature vector(MFCC) 15ê°œ frameìœ¼ë¡œ frame-level íŠ¹ì§• ìƒì„±<br />
2 fully-connected layer (1st : bottleneck feature - 512, activation function : ReLU, batch   normalization)</p>
</blockquote>

        </article>
        <div class="post-content">
         <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<div id="gitalk-container"></div>

<script data-no-instant type="text/javascript">
const gitalk = new Gitalk({
  clientID: '5304ae17c5ba0ce3b2aa',
  clientSecret: '22801b52c86101ff074072faa1631475954d2936',
  repo: 'arabae.github.io',
  owner: 'arabae',
  admin: ['arabae'],
  id: location.pathname,      // Ensure uniqueness and length less than 50
  distractionFreeMode: true  // Facebook-like distraction free mode
})

gitalk.render('gitalk-container')
</script>
        </div>
    </div>
</div>

    
    <footer id="footer" class="footer bg-white">
    <div class="footer-social">
        <div class="footer-container clearfix">
            <div class="social-list">
		<a href="/"><span class='iconfont icon-home'></span>&nbsp;&nbsp;HOME</a>
                <a rel="nofollow" target="_blank" href="https://github.com/arabae"><span class='iconfont icon-github'></span>&nbsp;&nbsp;Github</a>
                <a target="_blank" href="/feed.xml"><span class='iconfont icon-rss'></span>&nbsp;&nbsp;RSS</a>
            </div>
        </div>
    </div>
    <div class="footer-meta">
        <div class="footer-container">
            <div class="meta-item meta-copyright">
                <div class="meta-copyright-info">
                    <a href="https://github.com/arabae" class="info-logo">
                        <img src="/style/image/logo.png" alt="wonder">
                    </a>
                    <div class="info-text">
                        <p>Copyright &copy; 2021 - 2021 <a href="https://github.com/arabae"><code>ARa Bae</code></a></p>
                        <p>Powered by <a href="http://jekyllrb.com" target="_blank" rel="nofollow"><code>jekyll</code></a>ï¼Œtheme is <a href="https://github.com/lightfish-zhang/pinghsu-jekyll" target="_blank" rel="nofollow"><code>pinghsu</code></a></p>
                    </div>
                </div>
            </div>

            <div class="meta-item meta-posts">
                <h3 class="meta-title">RECENT POSTS</h3>
                
                    <li>
                        <a href="/2021-08-03-Conformer">Conformer: Convolution-augmented Transformer for Speech Recognition</a>
                    </li>
                
                    <li>
                        <a href="/2021-01-25-Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recognition">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>
                    </li>
                
                    <li>
                        <a href="/2020-10-13-Cross-Attentive-Pooling-for-SV">Cross attentive pooling for speaker verification</a>
                    </li>
                
                    <li>
                        <a href="/2020-10-06-Metric-Laerning-for-Keyword-Spotting">Metric Learning for Keyword Spotting</a>
                    </li>
                
                    <li>
                        <a href="/2019-07-30-Attention-based-models-for-TDSV">Attention-based Models For Text-dependent Speaker Verification</a>
                    </li>
                
                    <li>
                        <a href="/2019-07-24-TISV-with-Adversarial-Learning-on-Short-Utterances">Text-Independent Speaker Verification with Adversarial Learning on Short Utterances</a>
                    </li>
                
                    <li>
                        <a href="/2019-07-10-GE2E-loss-for-SV">Generalized End to End Loss For Speaker Verification</a>
                    </li>
                
            </div>

        </div>
    </div>
</footer>

<!-- #end -->
<script src="//cdn.bootcss.com/jquery/1.10.1/jquery.min.js"></script>
<script>
	!window.jQuery && document.write(unescape('%3Cscript src="/style/js/jquery.min.js"%3E%3C/script%3E'))
</script>
<script src="/style/js/headroom.min.js"></script>
<script src="/style/js/nav.min.js"></script>
<script type="text/javascript">
    var header = new Headroom(document.getElementById("header"), {
        tolerance: 10,
        offset : 80,
        classes: {
            initial: "animated",
            pinned: "slideDown",
            unpinned: "slideUp"
        }
    });
    header.init();
</script>

<script>window.SmoothScrollOptions = { stepSize: 36 }</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/smoothscroll/1.4.8/SmoothScroll.min.js"></script>
<script>
	!window.SmoothScroll && document.write(unescape('%3Cscript src="/style/js/SmoothScroll.min.js"%3E%3C/script%3E'))
</script>




  </body>
</html>
